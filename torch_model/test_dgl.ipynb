{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using backend: pytorch\n"
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/nfs/zty/Graph/Dynamic-Graph\")\n",
    "sys.path.append(\".\")\n",
    "from data_loader.minibatch import load_data\n",
    "from model.utils import get_free_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Namespace(gpu=True)\nsetGPU: Setting GPU to: 0\nINFO:root:Namespace(gpu=True)\nsetGPU: Setting GPU to: 0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'test_dgl' from '/nfs/zty/Graph/Dynamic-Graph/torch_model/test_dgl.py'>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import importlib\n",
    "import test_dgl\n",
    "importlib.reload(test_dgl)\n",
    "# from test_dgl import test_graph, construct_dglgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, nodes = test_dgl.test_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = test_dgl.construct_dglgraph(edges, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DGLGraph(num_nodes=10, num_edges=45,\n         ndata_schemes={'nfeat': Scheme(shape=(4,), dtype=torch.float32)}\n         edata_schemes={'timestamp': Scheme(shape=(), dtype=torch.float32), 'efeat': Scheme(shape=(1,), dtype=torch.float32)})"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "g.ndata[\"nfeat\"].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_func(edges):\n",
    "    # EdgesBatch: src.data, dst.data, data\n",
    "    print(\"msg func1\", edges.data[\"efeat\"].shape)\n",
    "    return {\"emsg\": edges.src[\"nfeat\"]}\n",
    "\n",
    "def message_func2(edges):\n",
    "    # EdgesBatch: src.data, dst.data, data\n",
    "    print(\"msg func2\")\n",
    "    return {\"emsg\": edges.src[\"nfeat\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_func(nodes):\n",
    "    # NodesBatch: mailbox\n",
    "    print(\"reduce func\", nodes.mailbox[\"emsg\"].shape)\n",
    "    return {\"nred\": torch.mean(nodes.mailbox[\"emsg\"], dim=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "msg func1 torch.Size([45, 1])\nreduce func torch.Size([1, 1, 4])\nreduce func torch.Size([1, 2, 4])\nreduce func torch.Size([1, 3, 4])\nreduce func torch.Size([1, 4, 4])\nreduce func torch.Size([1, 5, 4])\nreduce func torch.Size([1, 6, 4])\nreduce func torch.Size([1, 7, 4])\nreduce func torch.Size([1, 8, 4])\nreduce func torch.Size([1, 9, 4])\n"
    }
   ],
   "source": [
    "g.register_message_func(message_func)\n",
    "g.register_reduce_func(reduce_func)\n",
    "g.update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "msg func1 torch.Size([46, 1])\nreduce func torch.Size([1, 1, 4])\nreduce func torch.Size([1, 2, 4])\nreduce func torch.Size([1, 3, 4])\nreduce func torch.Size([1, 4, 4])\nreduce func torch.Size([1, 5, 4])\nreduce func torch.Size([1, 6, 4])\nreduce func torch.Size([1, 7, 4])\nreduce func torch.Size([1, 8, 4])\nreduce func torch.Size([1, 10, 4])\n"
    }
   ],
   "source": [
    "g.add_edge(8, 9)\n",
    "g.edata[\"timestamp\"][-1] = g.edata[\"timestamp\"].max() + 1\n",
    "g.update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('timestamp', torch.Size([46])), ('efeat', torch.Size([46, 1]))]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "[(k, g.edata[k].shape) for k in g.edata.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('nfeat', torch.Size([10, 4])), ('nred', torch.Size([10, 4]))]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "[(k, g.ndata[k].shape) for k in g.ndata.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "msg func2\nreduce func torch.Size([1, 1, 4])\nreduce func torch.Size([1, 2, 4])\nreduce func torch.Size([1, 3, 4])\nreduce func torch.Size([1, 4, 4])\nreduce func torch.Size([1, 5, 4])\nreduce func torch.Size([1, 6, 4])\nreduce func torch.Size([1, 7, 4])\nreduce func torch.Size([1, 8, 4])\nreduce func torch.Size([1, 10, 4])\n"
    }
   ],
   "source": [
    "g.register_message_func(message_func2)\n",
    "g.update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "max_degree = g.in_degrees().max()\n",
    "def reduce_padding(nodes):\n",
    "    # padding with neighbor degrees to max_degree\n",
    "    deg = nodes.mailbox[\"emsg\"].shape[1]\n",
    "    return {\"deg_embds\": F.pad(nodes.mailbox[\"emsg\"], (0, 0, 0, max_degree - deg), \"constant\", 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "msg func2\ntorch.Size([10, 10, 4])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [-0.9970,  0.8330, -0.0129, -2.2435],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [-0.9970,  0.8330, -0.0129, -2.2435],\n         [ 0.3173, -1.4975,  1.1729,  0.9561],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [-0.9970,  0.8330, -0.0129, -2.2435],\n         [ 0.3173, -1.4975,  1.1729,  0.9561],\n         [ 0.1679,  1.3227, -1.3530,  1.4325],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [-0.9970,  0.8330, -0.0129, -2.2435],\n         [ 0.3173, -1.4975,  1.1729,  0.9561],\n         [ 0.1679,  1.3227, -1.3530,  1.4325],\n         [-0.2166, -0.1543, -0.3290, -0.4450],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.7466, -2.3899, -1.1321,  0.9805],\n         [ 1.4682, -0.0885,  1.0883, -0.2492],\n         [-0.4624, -0.5191,  0.5656, -0.1710],\n         [-0.7000,  1.2897, -0.8471,  1.4051],\n         [-0.9970,  0.8330, -0.0129, -2.2435],\n         [ 0.3173, -1.4975,  1.1729,  0.9561],\n         [ 0.1679,  1.3227, -1.3530,  1.4325],\n         [-0.2166, -0.1543, -0.3290, -0.4450],\n         [ 0.2871, -2.4716, -0.0759, -1.4017],\n         [ 0.2871, -2.4716, -0.0759, -1.4017]]], grad_fn=<IndexSelectBackward>)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "g.register_reduce_func(reduce_padding)\n",
    "g.update_all()\n",
    "print(g.ndata[\"deg_embds\"].shape)\n",
    "g.ndata[\"deg_embds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['nfeat', 'nred', 'deg_embds']"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "list(g.ndata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DGLGraph(num_nodes=3, num_edges=3,\n         ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}\n         edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# subgraph feature mutation doesn't reflect the parent graph feature\n",
    "subg = g.subgraph([0, 1, 2])\n",
    "subg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n        [ 1.4682, -0.0885,  1.0883, -0.2492],\n        [-0.4624, -0.5191,  0.5656, -0.1710]], grad_fn=<CopySlices>)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "list(subg.ndata.keys())\n",
    "subg.copy_from_parent()\n",
    "subg.ndata[\"nfeat\"][0] = torch.ones_like(subg.ndata[\"nfeat\"][0])\n",
    "subg.ndata[\"nfeat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 0.7466, -2.3899, -1.1321,  0.9805],\n        [ 1.4682, -0.0885,  1.0883, -0.2492],\n        [-0.4624, -0.5191,  0.5656, -0.1710],\n        [-0.7000,  1.2897, -0.8471,  1.4051],\n        [-0.9970,  0.8330, -0.0129, -2.2435],\n        [ 0.3173, -1.4975,  1.1729,  0.9561],\n        [ 0.1679,  1.3227, -1.3530,  1.4325],\n        [-0.2166, -0.1543, -0.3290, -0.4450],\n        [ 0.2871, -2.4716, -0.0759, -1.4017],\n        [ 1.2816, -0.9382, -0.3057,  0.1287]], requires_grad=True)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "g.ndata[\"nfeat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['nfeat', 'nred', 'deg_embds']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n        [ 1.4682, -0.0885,  1.0883, -0.2492],\n        [-0.4624, -0.5191,  0.5656, -0.1710],\n        [-0.7000,  1.2897, -0.8471,  1.4051],\n        [-0.9970,  0.8330, -0.0129, -2.2435],\n        [ 0.3173, -1.4975,  1.1729,  0.9561],\n        [ 0.1679,  1.3227, -1.3530,  1.4325],\n        [-0.2166, -0.1543, -0.3290, -0.4450],\n        [ 0.2871, -2.4716, -0.0759, -1.4017],\n        [ 1.2816, -0.9382, -0.3057,  0.1287]], grad_fn=<CopySlices>)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "def foo(g):\n",
    "    gl = g.local_var()\n",
    "    gl.ndata[\"foo\"] = torch.ones((gl.number_of_nodes()))\n",
    "    gl.ndata[\"nfeat\"][0] = torch.zeros_like(gl.ndata[\"nfeat\"][0])\n",
    "# local_var makes overwrite the ndata \n",
    "foo(g)\n",
    "print(list(g.ndata.keys()))\n",
    "g.ndata[\"nfeat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.edata[\"efeat\"] = torch.ones_like(g.edata[\"efeat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 9, 1])\ntorch.Size([1, 8, 1])\ntorch.Size([1, 7, 1])\ntorch.Size([1, 6, 1])\ntorch.Size([1, 5, 1])\ntorch.Size([1, 4, 1])\ntorch.Size([1, 3, 1])\ntorch.Size([2, 2, 1])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['timestamp', 'efeat', 'next_feat']"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "def group_edges(edges):\n",
    "    print(edges.data[\"efeat\"].shape) # (bucket_size, degree, dim)\n",
    "    buc, deg, dim = edges.data[\"efeat\"].shape\n",
    "    # Mask1. compute timestamp mask before multiply over all edges of src/dst node\n",
    "    # ts = edges.data[\"timestamp\"].unsqueeze(-1) # (bucket_size, degree, 1)\n",
    "    # mask = ts.permute(0, 2, 1) <= ts # (bucket_size, degree, degree), computation complexity: bucket_size * degree^2\n",
    "    # Mask2. if the input batch is always increasing along dim-1, we can use an lower triangular boolean matrix instead of computing a mask matrix\n",
    "    orders = torch.argsort(edges.data[\"timestamp\"], dim=1)\n",
    "    assert torch.all(torch.eq(torch.arange(deg), orders)) # assert the timestamp is increasing\n",
    "    mask = torch.tril(torch.ones(deg, deg))\n",
    "    # print(mask)\n",
    "    # BMM: Mask(bucket_size, deg, deg) * Efeat(bucket_size, deg, dim) * W(dim, dim2)\n",
    "    if len(mask.shape) >= 3:\n",
    "        mask_feat = torch.bmm(mask.float(), edges.data[\"efeat\"]) # the same as sum over all valid neighbors\n",
    "    else:\n",
    "        mask_feat = torch.matmul(mask.float(), edges.data[\"efeat\"])\n",
    "    next_feat = torch.matmul(mask_feat, torch.ones(dim, 3)) # (bucket_size, deg, dim2)\n",
    "    return {\"next_feat\": next_feat}\n",
    "if len(g.edata[\"efeat\"].shape) < 2: g.edata[\"efeat\"] = g.edata[\"efeat\"].unsqueeze(-1)\n",
    "g.group_apply_edges(func=group_edges, group_by=\"src\")\n",
    "list(g.edata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [5., 5., 5.],\n        [6., 6., 6.],\n        [7., 7., 7.],\n        [8., 8., 8.],\n        [9., 9., 9.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [5., 5., 5.],\n        [6., 6., 6.],\n        [7., 7., 7.],\n        [8., 8., 8.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [5., 5., 5.],\n        [6., 6., 6.],\n        [7., 7., 7.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [5., 5., 5.],\n        [6., 6., 6.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [5., 5., 5.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [4., 4., 4.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [3., 3., 3.],\n        [1., 1., 1.],\n        [2., 2., 2.],\n        [1., 1., 1.],\n        [2., 2., 2.]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "g.edata[\"next_feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehop_conv(g, current_layer=1):\n",
    "    # we compute src_feat_layer and dst_feat_layer features for each edge per layer\n",
    "    \n",
    "    def src_feat_conv(edges):\n",
    "        '''Group by source nodes, computing the aggregation of destination ndoes.'''\n",
    "        previous_layer = current_layer - 1\n",
    "        if previous_layer <= 0:\n",
    "            h_self = edges.src[\"nfeat\"]\n",
    "            h_neighs = edges.dst[\"nfeat\"]\n",
    "        else:\n",
    "            h_self = edges.data[\"src_feat{}\".format(previous_layer)]\n",
    "            h_neighs = edges.data[\"dst_feat{}\".format(previous_layer)]\n",
    "        assert h_self.shape == h_neighs.shape # (bucket_size, deg, dim)\n",
    "        _, deg, dim = h_self.shape\n",
    "        # assert the timestamp is increasing\n",
    "        orders = torch.argsort(edges.data[\"timestamp\"], dim=1)\n",
    "        assert torch.all(torch.eq(torch.arange(deg), orders)) \n",
    "        mask = torch.tril(torch.ones(deg, deg)) \n",
    "        # neighbor aggregation via mean/gcn/meanpooling/maxpooling/lstm\n",
    "        # sum operation: (bucket_size, deg, dim) <= (deg, deg) * (bucket_size, deg, dim)\n",
    "        mask_feat = torch.matmul(mask, h_neighs) \n",
    "        # mask_feat = mask_feat / torch.sum(mask, dim=1, keepdim=True) # mean operation     \n",
    "        next_feat = torch.matmul(mask_feat, torch.ones(dim, 3))\n",
    "        return {\"src_feat{}\".format(current_layer): next_feat}\n",
    "    \n",
    "    def dst_feat_conv(edges):\n",
    "        '''Group by destionation nodes, computing the aggregation of source ndoes.'''\n",
    "        previous_layer = current_layer - 1\n",
    "        if previous_layer <= 0:\n",
    "            h_self = edges.src[\"nfeat\"]\n",
    "            h_neighs = edges.dst[\"nfeat\"]\n",
    "        else:\n",
    "            h_self = edges.data[\"src_feat{}\".format(previous_layer)]\n",
    "            h_neighs = edges.data[\"dst_feat{}\".format(previous_layer)]\n",
    "        h_self, h_neighs = h_neighs, h_self\n",
    "        assert h_self.shape == h_neighs.shape # (bucket_size, deg, dim)\n",
    "        _, deg, dim = h_self.shape\n",
    "        # assert the timestamp is increasing\n",
    "        orders = torch.argsort(edges.data[\"timestamp\"], dim=1)\n",
    "        assert torch.all(torch.eq(torch.arange(deg), orders)) \n",
    "        mask = torch.tril(torch.ones(deg, deg)) \n",
    "        # neighbor aggregation via mean/gcn/meanpooling/maxpooling/lstm\n",
    "        # sum operation: (bucket_size, deg, dim) <= (deg, deg) * (bucket_size, deg, dim)\n",
    "        mask_feat = torch.matmul(mask, h_neighs) \n",
    "        # mask_feat = mask_feat / torch.sum(mask, dim=1, keepdim=True) # mean operation     \n",
    "        next_feat = torch.matmul(mask_feat, torch.ones(dim, 3))\n",
    "        return {\"dst_feat{}\".format(current_layer): next_feat}\n",
    "    g.group_apply_edges(group_by=\"src\", func=src_feat_conv) # compute temporal embeddings for src nodes\n",
    "    g.group_apply_edges(group_by=\"dst\", func=dst_feat_conv) # compute temporal embeddings for dst nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nfeat torch.Size([10, 4])\nnred torch.Size([10, 4])\ndeg_embds torch.Size([10, 10, 4])\ntimestamp torch.Size([46])\nefeat torch.Size([46, 1])\nnext_feat torch.Size([46, 3])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[None, None, None]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "[print(k, g.ndata[k].shape) for k in g.ndata.keys()]\n",
    "[print(k, g.edata[k].shape) for k in g.edata.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['timestamp', 'efeat', 'src_feat1', 'dst_feat1', 'src_feat2', 'dst_feat2']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [24., 24., 24.],\n         [28., 28., 28.],\n         [32., 32., 32.],\n         [36., 36., 36.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [24., 24., 24.],\n         [28., 28., 28.],\n         [32., 32., 32.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [24., 24., 24.],\n         [28., 28., 28.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [24., 24., 24.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.]]),\n tensor([[ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 4.,  4.,  4.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [ 8.,  8.,  8.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [12., 12., 12.],\n         [16., 16., 16.],\n         [16., 16., 16.],\n         [16., 16., 16.],\n         [16., 16., 16.],\n         [16., 16., 16.],\n         [16., 16., 16.],\n         [20., 20., 20.],\n         [20., 20., 20.],\n         [20., 20., 20.],\n         [20., 20., 20.],\n         [20., 20., 20.],\n         [24., 24., 24.],\n         [24., 24., 24.],\n         [24., 24., 24.],\n         [24., 24., 24.],\n         [28., 28., 28.],\n         [28., 28., 28.],\n         [28., 28., 28.],\n         [32., 32., 32.],\n         [32., 32., 32.],\n         [36., 36., 36.],\n         [40., 40., 40.]]))"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "g.ndata[\"nfeat\"] = torch.ones_like(g.ndata[\"nfeat\"])\n",
    "onehop_conv(g, current_layer=1)\n",
    "print(list(g.edata.keys()))\n",
    "g.edata[\"src_feat1\"], g.edata[\"dst_feat1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['timestamp', 'efeat', 'src_feat1', 'dst_feat1', 'src_feat2', 'dst_feat2']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[ 12.,  12.,  12.],\n         [ 24.,  24.,  24.],\n         [ 36.,  36.,  36.],\n         [ 48.,  48.,  48.],\n         [ 60.,  60.,  60.],\n         [ 72.,  72.,  72.],\n         [ 84.,  84.,  84.],\n         [ 96.,  96.,  96.],\n         [108., 108., 108.],\n         [ 24.,  24.,  24.],\n         [ 48.,  48.,  48.],\n         [ 72.,  72.,  72.],\n         [ 96.,  96.,  96.],\n         [120., 120., 120.],\n         [144., 144., 144.],\n         [168., 168., 168.],\n         [192., 192., 192.],\n         [ 36.,  36.,  36.],\n         [ 72.,  72.,  72.],\n         [108., 108., 108.],\n         [144., 144., 144.],\n         [180., 180., 180.],\n         [216., 216., 216.],\n         [252., 252., 252.],\n         [ 48.,  48.,  48.],\n         [ 96.,  96.,  96.],\n         [144., 144., 144.],\n         [192., 192., 192.],\n         [240., 240., 240.],\n         [288., 288., 288.],\n         [ 60.,  60.,  60.],\n         [120., 120., 120.],\n         [180., 180., 180.],\n         [240., 240., 240.],\n         [300., 300., 300.],\n         [ 72.,  72.,  72.],\n         [144., 144., 144.],\n         [216., 216., 216.],\n         [288., 288., 288.],\n         [ 84.,  84.,  84.],\n         [168., 168., 168.],\n         [252., 252., 252.],\n         [ 96.,  96.,  96.],\n         [192., 192., 192.],\n         [108., 108., 108.],\n         [228., 228., 228.]]),\n tensor([[ 12.,  12.,  12.],\n         [ 24.,  24.,  24.],\n         [ 36.,  36.,  36.],\n         [ 48.,  48.,  48.],\n         [ 60.,  60.,  60.],\n         [ 72.,  72.,  72.],\n         [ 84.,  84.,  84.],\n         [ 96.,  96.,  96.],\n         [108., 108., 108.],\n         [ 36.,  36.,  36.],\n         [ 60.,  60.,  60.],\n         [ 84.,  84.,  84.],\n         [108., 108., 108.],\n         [132., 132., 132.],\n         [156., 156., 156.],\n         [180., 180., 180.],\n         [204., 204., 204.],\n         [ 72.,  72.,  72.],\n         [108., 108., 108.],\n         [144., 144., 144.],\n         [180., 180., 180.],\n         [216., 216., 216.],\n         [252., 252., 252.],\n         [288., 288., 288.],\n         [120., 120., 120.],\n         [168., 168., 168.],\n         [216., 216., 216.],\n         [264., 264., 264.],\n         [312., 312., 312.],\n         [360., 360., 360.],\n         [180., 180., 180.],\n         [240., 240., 240.],\n         [300., 300., 300.],\n         [360., 360., 360.],\n         [420., 420., 420.],\n         [252., 252., 252.],\n         [324., 324., 324.],\n         [396., 396., 396.],\n         [468., 468., 468.],\n         [336., 336., 336.],\n         [420., 420., 420.],\n         [504., 504., 504.],\n         [432., 432., 432.],\n         [528., 528., 528.],\n         [540., 540., 540.],\n         [564., 564., 564.]]))"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "onehop_conv(g, current_layer=2)\n",
    "print(list(g.edata.keys()))\n",
    "g.edata[\"src_feat2\"], g.edata[\"dst_feat2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['timestamp', 'efeat', 'src_feat1', 'dst_feat1', 'src_feat2', 'dst_feat2', 'src_feat3', 'dst_feat3']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[  36.,   36.,   36.],\n         [ 108.,  108.,  108.],\n         [ 216.,  216.,  216.],\n         [ 360.,  360.,  360.],\n         [ 540.,  540.,  540.],\n         [ 756.,  756.,  756.],\n         [1008., 1008., 1008.],\n         [1296., 1296., 1296.],\n         [1620., 1620., 1620.],\n         [ 108.,  108.,  108.],\n         [ 288.,  288.,  288.],\n         [ 540.,  540.,  540.],\n         [ 864.,  864.,  864.],\n         [1260., 1260., 1260.],\n         [1728., 1728., 1728.],\n         [2268., 2268., 2268.],\n         [2880., 2880., 2880.],\n         [ 216.,  216.,  216.],\n         [ 540.,  540.,  540.],\n         [ 972.,  972.,  972.],\n         [1512., 1512., 1512.],\n         [2160., 2160., 2160.],\n         [2916., 2916., 2916.],\n         [3780., 3780., 3780.],\n         [ 360.,  360.,  360.],\n         [ 864.,  864.,  864.],\n         [1512., 1512., 1512.],\n         [2304., 2304., 2304.],\n         [3240., 3240., 3240.],\n         [4320., 4320., 4320.],\n         [ 540.,  540.,  540.],\n         [1260., 1260., 1260.],\n         [2160., 2160., 2160.],\n         [3240., 3240., 3240.],\n         [4500., 4500., 4500.],\n         [ 756.,  756.,  756.],\n         [1728., 1728., 1728.],\n         [2916., 2916., 2916.],\n         [4320., 4320., 4320.],\n         [1008., 1008., 1008.],\n         [2268., 2268., 2268.],\n         [3780., 3780., 3780.],\n         [1296., 1296., 1296.],\n         [2880., 2880., 2880.],\n         [1620., 1620., 1620.],\n         [3312., 3312., 3312.]]),\n tensor([[  36.,   36.,   36.],\n         [  72.,   72.,   72.],\n         [ 108.,  108.,  108.],\n         [ 144.,  144.,  144.],\n         [ 180.,  180.,  180.],\n         [ 216.,  216.,  216.],\n         [ 252.,  252.,  252.],\n         [ 288.,  288.,  288.],\n         [ 324.,  324.,  324.],\n         [ 144.,  144.,  144.],\n         [ 252.,  252.,  252.],\n         [ 360.,  360.,  360.],\n         [ 468.,  468.,  468.],\n         [ 576.,  576.,  576.],\n         [ 684.,  684.,  684.],\n         [ 792.,  792.,  792.],\n         [ 900.,  900.,  900.],\n         [ 360.,  360.,  360.],\n         [ 576.,  576.,  576.],\n         [ 792.,  792.,  792.],\n         [1008., 1008., 1008.],\n         [1224., 1224., 1224.],\n         [1440., 1440., 1440.],\n         [1656., 1656., 1656.],\n         [ 720.,  720.,  720.],\n         [1080., 1080., 1080.],\n         [1440., 1440., 1440.],\n         [1800., 1800., 1800.],\n         [2160., 2160., 2160.],\n         [2520., 2520., 2520.],\n         [1260., 1260., 1260.],\n         [1800., 1800., 1800.],\n         [2340., 2340., 2340.],\n         [2880., 2880., 2880.],\n         [3420., 3420., 3420.],\n         [2016., 2016., 2016.],\n         [2772., 2772., 2772.],\n         [3528., 3528., 3528.],\n         [4284., 4284., 4284.],\n         [3024., 3024., 3024.],\n         [4032., 4032., 4032.],\n         [5040., 5040., 5040.],\n         [4320., 4320., 4320.],\n         [5616., 5616., 5616.],\n         [5940., 5940., 5940.],\n         [6624., 6624., 6624.]]))"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "onehop_conv(g, current_layer=3)\n",
    "print(list(g.edata.keys()))\n",
    "g.edata[\"src_feat3\"], g.edata[\"dst_feat3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bittorchconda04cad82f890446768c932663666f3c77",
   "display_name": "Python 3.6.10 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}